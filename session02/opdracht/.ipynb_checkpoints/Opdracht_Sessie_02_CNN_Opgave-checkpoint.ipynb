{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep learning -  Opdracht sessie 02 - CNN\n",
    "\n",
    "## Doelstelling van de opdracht\n",
    "\n",
    "Op het vlak van image recognition zijn de convolutional neural networks (en varianten ervan) nagenoeg onovertroffen.\n",
    "In deze opdracht zullen ze worden ingezet voor het herkennen van kledij, gezichtsexpressies en tot slot bij een autodetectiesysteem. Bij het uitvoeren ervan zal je leren hoe deze CNN's werken en welke hyperparameters getuned moeten worden. Bovendien zal je werken met kleurafbeeldingen waardoor je 4D tensors bekomt (3D afbeeldingen + 1 dimensie voor alle gestackte afbeeldingen).\n",
    "Naast het trainen van een eigen ontworpen CNN zal je ook gebruik maken van pretrained netwerken en deze via transfer learning deels hertrainen in functie van jouw eigen classificatieprobleem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "import matplotlib.image as mpimg\n",
    "from skimage.io import imread, imsave, imshow\n",
    "from skimage import data, color, io, filters, morphology,transform, exposure, feature, util\n",
    "from scipy import ndimage\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, BatchNormalization\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.applications.vgg19 import VGG19\n",
    "from tensorflow.keras.applications.vgg19 import preprocess_input, decode_predictions\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "import re\n",
    "\n",
    "#K.set_image_dim_ordering('tf')\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "pd.set_option('display.max_rows',1000)\n",
    "pd.set_option('display.max_columns',1000)\n",
    "\n",
    "\n",
    "# GPU support \n",
    "\n",
    "#physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(physical_devices[0], True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Malaria Classification\n",
    "\n",
    "Ontwerp en train een CNN dat is in staat is met Malaria geïnfecteerde cellen van niet-geïnfecteerde cellen te onderscheiden.\n",
    "\n",
    "De data is te vinden in:\n",
    "- './Malaria/train/infected/': afbeelding van met Malaria geïnfecteerde cellen om mee te trainen.\n",
    "- './Malaria/train/uninfected/': afbeeldingen van gezonde, niet-geïnfecteerde cellen om mee te trainen.\n",
    "- './Malaria/test/infected/': afbeelding van met Malaria geïnfecteerde cellen om mee te testen.\n",
    "- './Malaria/test/uninfected/': afbeeldingen van gezonde, niet-geïnfecteerde cellen om mee te testen.\n",
    "\n",
    "\n",
    "1. Ontwerp in eerste instantie een eigen CNN. \n",
    "- Probeer de accuracy van het CNN op de test data zo hoog mogelijk te krijgen. Dit kan bijvoorbeeld omvatten: hyperparameter tuning van de het netwerk zelf, early stopping, image augmentation of eigen bedachte (pre)-processing technieken. \n",
    "- Stel nu dat aan het CNN de vereiste wordt gesteld dat het aantal false negatives (het netwerk voorspelt niet-geïnfecteerd terwijl ze wel geïnfecteerd zijn) op de test set maximaal 1% mag bedragen. Welke aanpassingen zou je doen? Voor deze aanpassingen uit en toon aan dat het aantal false negatives tot maximum 1% is gezakt. Welke accuracy haal je nog?\n",
    "\n",
    "2. Voer transfer learning uit. Hertrain het VGG19 netwerk voor het classificeren van de al dan niet met Malaria geïnfecteerde cellen. Vergelijk de resultaten met deze van het eigen CNN in termen van accuraatheid, f1-score, snelheid van training, de benodigde hoeveelheid training data, etc.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Malaria detection via eigen CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inlezen van de data\n",
    "\n",
    "# Lezen en preprocessen \n",
    "\n",
    "image_size = 100  # hoogte en breedte van de afbeeldingen na resizing. Pas gerust aan.\n",
    "nr_train_images = 1000  # Om het aantal afbeelding in de training set te beperken. Verhoog indien jouw systeem het toelaat.\n",
    "nr_test_images = 1000 # Om het aantal afbeelding in de test set in eerste instantiete beperken. \n",
    "infected_train_images = []\n",
    "infected_test_images = []\n",
    "uninfected_train_images = []\n",
    "uninfected_test_images = []\n",
    "y_infected_train = []\n",
    "y_uninfected_train = []\n",
    "y_infected_test = []\n",
    "y_uninfected_test =[]\n",
    "\n",
    "# read infected train_images\n",
    "path = './Malaria/train/infected/'\n",
    "valid_images = [\".jpg\",\".gif\",\".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_train_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path,f)) \n",
    "    im = transform.resize(im,(image_size,image_size),mode='constant',anti_aliasing=True)\n",
    "    infected_train_images.append(im)\n",
    "    y_infected_train.append(1)\n",
    "    \n",
    "# read infected test_images\n",
    "\n",
    "path = './Malaria/test/infected/'\n",
    "valid_images = [\".jpg\",\".gif\",\".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_test_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path,f))\n",
    "    im = transform.resize(im,(image_size,image_size),mode='constant',anti_aliasing=True)\n",
    "    infected_test_images.append(im)\n",
    "    y_infected_test.append(1)\n",
    "    \n",
    "\n",
    "# read uninfected train_images\n",
    "path = './Malaria/train/uninfected/'\n",
    "valid_images = [\".jpg\",\".gif\",\".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_train_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path,f)) \n",
    "    im = transform.resize(im,(image_size,image_size),mode='constant',anti_aliasing=True)\n",
    "    uninfected_train_images.append(im)\n",
    "    y_uninfected_train.append(0)\n",
    "\n",
    "\n",
    "# read uninfected test_images\n",
    "\n",
    "path = './Malaria/test/uninfected/'\n",
    "valid_images = [\".jpg\",\".gif\",\".png\"]\n",
    "\n",
    "for f in os.listdir(path)[:nr_test_images]:\n",
    "    ext = os.path.splitext(f)[1]\n",
    "    if ext.lower() not in valid_images:\n",
    "        continue\n",
    "    im = imread(os.path.join(path,f)) \n",
    "    im = transform.resize(im,(image_size,image_size),mode='constant',anti_aliasing=True)\n",
    "    uninfected_test_images.append(im)\n",
    "    y_uninfected_test.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uitwerking Malaria detectie\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusies\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer learning\n",
    "Hertrain het VGG19 netwerk (of optioneel ResNet) op de malaria dataset. Vergelijk de resultaten met deze van het eigen CNN in termen van accuraatheid, f1-score, snelheid van training, de benodigde hoeveelheid training data, etc.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uitwerking transfer learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conclusies transfer learning\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Facial expressions classification\n",
    "\n",
    "Het bestand (\"facial_expressions.csv\") bevat tienduizenden afbeeldingen met gezichtsexpressies.\n",
    "Elke grijsafbeelding is 48x48 pixels groot en behoort tot één van de volgende 7 klasses:\n",
    "(0=Boos, 1=Afkeer, 2=Bang, 3=Blij, 4=Verdrietig, 5=Verrast, 6=Neutraal)\n",
    "\n",
    "De dataset is verdeeld in drie stukken:\n",
    "1. 'Training' gebruikt voor training.\n",
    "2. 'PrivateTest' gebruikt voor testing.\n",
    "3. 'PublicTest' gebruikt voor evaluatie bij publieke competities (hier niet nodig).\n",
    "Je kan filteren via de 'USAGE' kolom\n",
    "\n",
    "Een bijkomende moeilijkheid is dat de pixelintensiteiten van een afbeelding als 1 string zijn opgeslagen gescheiden door een spatie. Je zal zelf deze string moeten opsplitsen in individuele pixels.\n",
    "\n",
    "- De bedoeling is om een zo performant mogelijke CNN te trainen in termen van accuracy.\n",
    "- Bekijk de confusion matrix. Zijn er expressies die meer of minder goed herkend worden?\n",
    "- Welke expressies worden het meest met elkaar verward. Baseer je ook hier op de confusion matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion</th>\n",
       "      <th>pixels</th>\n",
       "      <th>Usage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>35882</th>\n",
       "      <td>6</td>\n",
       "      <td>50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35883</th>\n",
       "      <td>3</td>\n",
       "      <td>178 174 172 173 181 188 191 194 196 199 200 20...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35884</th>\n",
       "      <td>0</td>\n",
       "      <td>17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35885</th>\n",
       "      <td>3</td>\n",
       "      <td>30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35886</th>\n",
       "      <td>2</td>\n",
       "      <td>19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...</td>\n",
       "      <td>PrivateTest</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       emotion                                             pixels        Usage\n",
       "35882        6  50 36 17 22 23 29 33 39 34 37 37 37 39 43 48 5...  PrivateTest\n",
       "35883        3  178 174 172 173 181 188 191 194 196 199 200 20...  PrivateTest\n",
       "35884        0  17 17 16 23 28 22 19 17 25 26 20 24 31 19 27 9...  PrivateTest\n",
       "35885        3  30 28 28 29 31 30 42 68 79 81 77 67 67 71 63 6...  PrivateTest\n",
       "35886        2  19 13 14 12 13 16 21 33 50 57 71 84 97 108 122...  PrivateTest"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('./facial_expressions.csv')\n",
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Car detection system\n",
    "\n",
    "De uiteindelijke bedoeling is om een werkende car detector te bouwen die in staat is om in een afbeelding (of video) auto's met een hoge accuraatheid te detecteren en er een bounding box omheen te tekenen, zoals op onderstaand voorbeeld.\n",
    "\n",
    "![alt text](./JupyterImages/cardetectionExample.png \"Title\")\n",
    "\n",
    "De opdracht kan in twee stukken opgedeeld worden:\n",
    "1. Trainen van een CNN voor het classificeren van auto's. \n",
    "2. Detectie van de auto's in een afbeelding door met een in grootte variërend window de afbeelding af te scannen en elke subafbeelding door de in stap 1 getrainde classifiër te sturen.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stap 1. Car classifier\n",
    "\n",
    "De map \"vehicles\" bevat duizenden kleurafbeeldingen van auto's, de map \"non-vehicles\" van niet-auto's.\n",
    "\n",
    "- Maak van deze afbeeldingen gebruik om een accurate binaire CNN classifier (auto of niet-auto) te trainen. Bepaal daarbij zelf de architectuur, hyperparamters, grootte van test- en training set.\n",
    "\n",
    "- Hertrain het VGG19-net als car detector. Vergelijk de accuracy met de accuracy van het eigen ontworpen CNN.\n",
    "\n",
    "**Opmerkingen:**\n",
    "\n",
    "- Omwille van het groot aantal afbeeldingen is het inladen ervan vrij geheugenintensief. Daarom is het aan te raden maar een deel van de afbeeldingen te gebruiken. Achteraf kan je de dataset uitbreiden als jouw computer dat toelaat.\n",
    "- Normaliseer de afbeeldingen naar floats tussen 0 en 1.\n",
    "\n",
    "```Python\n",
    "X_car = X_car.astype('float32')`\n",
    "X_car /= 255```\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uitwerking van de car classifier\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stap 2.  Sliding window detection\n",
    "\n",
    "Om nu een auto te detecteren in een grotere afbeelding (locatie van de auto in een foto) ga je als volgt te werk:\n",
    "Via een for loop kan je de afbeelding meerdere malen afscannen telkens met een in grootte varierend window. Classificeer nu telkens de subafbeelding die zich onder het window bevindt. Teken een bounding box rond de gedetecteerde auto.\n",
    "Gebruik als classifier ofwel het eigen CNN of de hertrainde VGG19 classifier.\n",
    "\n",
    "In de map \"StreetImages\" zitten enkele afbeeldingen die je kan gebruiken om de detector op los te laten\n",
    "\n",
    "Belangrijk is niet alleen te optimalizeren voor detectie accuraatheid maar ook naar **detectiesnelheid**.\n",
    "\n",
    "Voor het tekenen van de bounding box kan volgende code gebruikt worden:\n",
    "```python\n",
    "def rectangle_perimeter(r0, c0, width, height, shape=None, clip=False):\n",
    "    rr, cc = [r0, r0 + width, r0 + width, r0], [c0, c0, c0 + height, c0 + height]\n",
    "    return skimage.draw.polygon_perimeter(rr, cc, shape=shape, clip=clip)\n",
    "\n",
    "# tekenen van bounding box:\n",
    "rr, cc = rectangle_perimeter(y, x, w, w)\n",
    "image_detected[rr,cc] =255\n",
    "\n",
    "```\n",
    "\n",
    "Eenzelfde auto zal normaal gezien door meerdere boundingboxes aangeduid zijn. Zoek een manier om boundingboxes die heel dicht op elkaar liggen tot één enkele bounding box te herleiden.\n",
    "\n",
    "Een methode die in de praktijk dikwijls toepast wordt om redundantie boundingboxes te verwijderen is de Non-Maximum Suppression. Meer info is te vinden op https://www.pyimagesearch.com/2014/11/17/non-maximum-suppression-object-detection-python/\n",
    "Het is niet vereist deze non-maximum suppression bij deze opdracht toe te passen. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uitwerking sliding window detection.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
